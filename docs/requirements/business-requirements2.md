NutriVision Live: Multimodal Grocery & Cosmetics Co-Pilot (Business & UX Blueprint)1. Executive Summary & Market PositioningThe Core Pitch: "NutriVision Live is a zero-typing, real-time German ‚ÄòYuka++‚Äô agent that sees products through your smartphone camera, auto-identifies them, grounds its answers in Open Facts and EU rules, and speaks concise, interruptible verdicts."Market research indicates that 75 percent of consumers in Germany strongly desire greater transparency regarding the ingredients in their food and cosmetic products. While applications like Yuka and CodeCheck currently dominate this space, their user experience remains heavily friction-based: users must manually align a barcode, wait for a database query, and then interpret a static, text-heavy screen.NutriVision Live fundamentally disrupts this paradigm. Built specifically for the Gemini Live Agent Challenge, it transitions the user experience from a "scanning tool" to an ambient, hands-free "shopping co-pilot." Utilizing multimodal AI, the user simply holds a product in front of their camera and asks natural questions. The agent visually identifies the item, processes its nutritional and toxicological data, and provides instant, conversational advice, all while overlaying a highly readable Augmented Reality (AR) summary on the screen.2. Hackathon Alignment & Devpost StrategyThe project is meticulously engineered to score maximum points against the Gemini Live Agent Challenge judging rubric:Innovation & Multimodal UX (40%): NutriVision breaks the "text box" paradigm completely. It features a continuous see/hear/speak loop. It proves true multimodality by combining real-time visual parsing (packaging and barcodes) with natural voice interactions.Avoiding Hallucinations (Grounded Outputs): Judges penalize AI that guesses. NutriVision strictly grounds its spoken advice in authoritative European databases (Open Food Facts, Open Beauty Facts) and explicit EU regulatory frameworks (EFSA, CosIng).The "Germany-First" Persona: The agent is designed with a strict but helpful German nutritionist persona, recognizing German packaging nuances, local expiration date formats, and European Union compliance standards.Strategic Scope: MVP vs. BetaTo ensure a flawless presentation for the judges, the product scope is strategically divided:The MVP (Must be Flawless): Food and beverage scanning. This will form the core of the demo.The "Wow" Factor (Beta Module): Personal care and cosmetics scanning. This will be visibly toggled in the UI as a "Beta" feature to demonstrate extreme innovation without risking the stability of the core food demo.3. The "Barcode-First" Identification StrategyTo guarantee the "feels live" speed required to win the hackathon and to eliminate AI hallucinations, the business logic employs a tiered, barcode-first identification pipeline. Relying purely on visual text extraction for product identification in a crowded supermarket often leads to selecting the wrong product variant.Primary (Silent & Invisible): As the user holds the product, the app silently detects the barcode in the camera frame. This triggers an instant, deterministic lookup.Secondary (Vision Fallback): If the barcode is obscured, the agent reads the brand and product name from the front label packaging and executes a highly confident text-based search.Tertiary (Disambiguation): If the visual scan is ambiguous, the agent asks a fast, natural question: "Do you mean the standard Nutella or the Plant-Based version?"4. Hyper-Detailed User Experience (UX) FlowThe interface is a Zero-UI, Voice-First paradigm, meaning there are no buttons to push or text boxes to type in during the core flow.Natural Interrogation & Barge-In: The user holds a local German product and asks, "Ist das gut f√ºr meine Di√§t?" (Is this good for my diet?). The agent responds naturally. If the user interrupts mid-sentence with, "Warte, wie viel Zucker?" (Wait, how much sugar?), the agent instantly halts its current speech and pivots to answer the specific question about sugar content.The Explainable AR "HUD" Overlay: Because audio alone can be difficult to reference later, identifying a product instantly triggers a mixed-reality "Heads-Up Display" card on the camera feed. This is highly demo-friendly for the judges:Primary Badges: Large A‚ÄìE (Nutri-Score) and 1‚Äì4 (NOVA) indicators.Traffic Light Bars: Simple, horizontal visual bars for Sugars, Salt, Saturated Fat, and Calories, color-coded Green (Low), Yellow (Medium), and Red (High) per 100g.Additive Flags: Instantly recognizable icons highlighting flagged ingredients (e.g., ‚ö†Ô∏è for hyperactivity warnings, üö´ for banned substances, üåø for safe).Dynamic Expiration Date Reading (German Legal Context): The agent visually parses printed dates on the physical packaging, making a critical legal distinction:Mindesthaltbarkeitsdatum (MHD): If the AI reads "Mindestens haltbar bis" and the date has passed, it verbally advises the user to rely on a sensory check (smell/taste) to prevent unnecessary food waste.Verbrauchsdatum: If the AI reads "Zu verbrauchen bis" (Use by) on highly perishable items, it issues a strict, non-negotiable warning to discard the product immediately for safety.5. Food Scoring Engine & Regulatory Logic (The MVP)Unlike existing applications that utilize proprietary, black-box algorithms, NutriVision's scoring is 100% transparent and grounded in the strictest, most recent European regulations.A. Nutritional Quality (50% Weighting)The agent uses the newly updated 2024 European Nutri-Score algorithm, which is significantly stricter than previous iterations.The Beverage Penalty: The agent recognizes that under the 2024 rules, artificially sweetened beverages suffer a strict 4-point penalty to discourage replacing sugar with non-nutritive sweeteners. Water remains the only beverage that can achieve a Grade A.The Red Meat Penalty: The agent applies specific penalties to red meat (beef, pork, lamb), allowing it to intelligently explain to a user why a chicken sausage scored higher than a pork sausage.B. Processing Risks (20% Weighting)The agent evaluates the food matrix using the NOVA Classification System. If a product scores a NOVA 4, the agent automatically triggers a conversational warning about the health impacts of ultra-processed, highly industrialized foods, regardless of how low the calorie count is.C. Additive Toxicology (20% Weighting)The agent cross-references ingredient lists against European Food Safety Authority (EFSA) data.Banned Substances: Instantly flags and warns against E171 (Titanium Dioxide), which was officially banned in EU food in 2022.Mandatory Behavioral Warnings: Actively flags specific artificial azo dyes (E102, E104, E110, E122, E124, E129). If detected, the agent verbally issues the EU-mandated warning that the product "may have an adverse effect on activity and attention in children."D. Environmental Impact (10% Weighting)Integrates the Eco-Score (Green-Score) to summarize the product's environmental footprint, rewarding organic certifications and recyclable packaging.6. Cosmetics & Personal Care Engine (The "Beta" Module)To achieve feature parity with market leaders, the "Beta" module evaluates shampoos, toothpastes, and skincare creams by parsing the INCI (International Nomenclature of Cosmetic Ingredients) list against the official EU Commission CosIng Database.Regulatory Guardrails: The agent never claims a product is "illegal" without proof. Instead, it utilizes CosIng data to state if an ingredient is on the Annex II (Prohibited) or Annex III (Restricted/Concentration Limits) lists.Endocrine Disruptors & Sensitizers: The agent actively scans for high-risk chemicals, such as long-chain parabens (e.g., isobutylparaben) and triclosan.Formaldehyde Releasers: Scans for hidden risks like DMDM hydantoin or imidazolidinyl urea, which slowly release formaldehyde over time, advising users with sensitive skin to seek alternatives.Microplastics: Flags intentionally added microplastics (e.g., polyethylene microbeads) in rinse-off products, referencing recent EU restriction initiatives.7. The Devpost Submission: 4-Minute Demo Video ScriptBecause the "Demo & Presentation" accounts for 30% of the final hackathon score, the video submission will follow a tightly choreographed, high-impact script:0:00 ‚Äì 0:20 (The Problem): Show a user frustrated with manually scanning a barcode on a traditional app and reading a tiny screen. Introduce the "Zero-UI" NutriVision Live.0:20 ‚Äì 1:30 (Core Live Demo - Food): The user holds a German snack product in front of the camera. The barcode is auto-detected. The agent speaks a natural, 2-sentence verdict. Crucial Moment: The user interrupts mid-sentence ("Warte, wie viel Salz?"). The agent stops instantly and answers with the exact salt content. The visual AR traffic-light chart appears on screen.1:30 ‚Äì 2:30 (Additives & Expiration Wow Factor): The user shows a brightly colored candy. The agent instantly flags the E122 dye and speaks the EU hyperactivity warning. Next, the user shows an expired "MHD" date on a canned good; the agent reads it visually and advises a sensory check rather than throwing it away.2:30 ‚Äì 3:30 (Cosmetics Beta): The user toggles to the personal care mode and scans a bottle of shampoo. The agent cross-references the CosIng database and gently flags a harsh sulfate and a restricted fragrance allergen, suggesting a cleaner alternative for sensitive skin.3:30 ‚Äì 4:00 (Proof of Grounding): Briefly flash the UI debug drawer showing the exact JSON tool calls happening in the background, proving to the judges that the AI is grounded in real data and is not hallucinating. Conclude with the project's value proposition.


NutriVision Live: Multimodal Grocery & Cosmetics Co-PilotPlan 1: Business Strategy, UX/UI, and Hackathon Alignment1. Executive Summary & Core PositioningCore Pitch: ‚ÄúNutriVision Live is a zero-typing, real-time German ‚ÄòYuka++‚Äô agent that sees products through your camera, auto-identifies them (barcode-first + packaging fallback), grounds answers in Open Facts + EU rules, and speaks concise, interruptible verdicts.‚ÄùNutriVision AI transcends traditional, static barcode scanners by utilizing the Gemini Multimodal Live API to create an ambient, hands-free consumer protection co-pilot. Built specifically for the German market, the agent synthesizes live camera feeds with strict EU regulatory data to evaluate food and personal care products instantly.2. User Experience (UX) and Interface DesignTo satisfy the Gemini Live Agent Challenge's "Innovation & Multimodal UX" criteria (40% of the judging weight), the application operates on a Zero-UI, Voice-First paradigm, augmented by an instantly readable visual overlay.Real-Time Vision & Voice: The user points their smartphone camera at a product (e.g., a German yogurt brand or a bottle of shampoo). The user asks naturally, "Is this good for my diet?" or "Will this irritate my skin?"Barge-In (Interruptibility): The agent speaks its verdict naturally. If the user interrupts ("Wait, how much sugar?"), the agent instantly stops speaking, flushes its audio buffer, and answers the specific question.Dynamic HUD (Heads-Up Display) Overlay: While the UI has no text input boxes, identifying a product triggers a "mixed reality" summary card on the camera feed:Nutri-Score/Eco-Score Badge: Displays A-E grades dynamically.Traffic Light Bars: Simple, horizontal visual bars for Sugar, Salt, Saturated Fat, and Calories (Green = Low, Yellow = Medium, Red = High).Additive Flags: Icons highlighting ‚ö†Ô∏è (Warning), üö´ (Not Authorized in EU), or üåø (Safe).Expiration Date Reading (German Localization): The agent visually parses printed dates on packaging, differentiating between Mindesthaltbarkeitsdatum ("Best Before" - advises sensory check to reduce food waste) and Verbrauchsdatum ("Use By" - strictly advises discarding if expired for safety).3. Business Logic: Nutritional & Cosmetic Scoring EngineThe application's core value relies on reproducible, deterministic scoring grounded in authoritative data, heavily avoiding AI hallucinations.Food Evaluation (Open Food Facts):Nutritional Quality (50%): Utilizes the 2024 updated European Nutri-Score algorithm. The agent understands that under the new rules, artificially sweetened beverages suffer a 4-point penalty, red meat is penalized compared to poultry, and water is the only beverage eligible for a Grade A.Processing Risks (20%): Utilizes the NOVA classification (1-4). A NOVA 4 score triggers an automatic "ultra-processed" conversational warning.Additive Toxicology (20%): Grounded in EFSA (European Food Safety Authority) regulations. The agent flags banned substances like E171 (Titanium Dioxide, banned in EU food since 2022) , and triggers mandatory behavioral warnings for specific artificial colorants (E102, E104, E110, E122, E124, E129) linked to hyperactivity in children.Eco-Impact (10%): Utilizes the Eco-Score/Green-Score (A-E) to summarize environmental footprint.Cosmetics Evaluation (Open Beauty Facts - "Beta" Feature):Regulatory Guardrails: Scans the INCI ingredient list against the EU Commission‚Äôs CosIng database. Identifies strictly prohibited substances (Annex II) and restricted substances (Annex III).High-Risk Flags: The agent actively scans for Endocrine Disruptors (e.g., long-chain parabens, triclosan), Formaldehyde-releasing preservatives (DMDM hydantoin), and severe allergens.4. Hackathon Strategy & Devpost SubmissionMVP Scope: Ensure the Food Scanning module is absolutely flawless for the demo. The Personal Care (Cosmetics) module will be visibly toggled and labeled "Beta" to demonstrate innovation without risking the core demo's stability.90-Second Demo Script:0:00 - 0:20: Scan a common snack. Agent auto-detects the barcode, speaks a 2-sentence verdict. User interrupts ("How much salt?"), agent stops and answers accurately. HUD overlay appears.0:20 - 0:40: Scan a candy with E122. Agent instantly flags the EU warning colorant ("May affect attention in children").0:40 - 0:60: Show an expired "MHD" date on a can. Agent reads it and advises a sensory check (smell/taste) rather than immediate disposal.0:60 - 1:30: Toggle "Beta" cosmetics mode. Scan a shampoo. Agent highlights harsh sulfates and fragrance allergens, referencing EU restrictions.Plan 2: Technical Architecture and Engineering Blueprint1. High-Level Architecture & GCP InfrastructureTo score maximum points in the "Technical Implementation" category, the backend is built entirely on Google Cloud Platform (GCP), optimized for sub-second latency.Frontend (Web/Mobile): Captures 16kHz, 16-bit PCM audio and ~1 FPS video frames. Streams these via WebSocket to the proxy. Handles local barcode detection (ZXing/ML Kit) to pass directly to the backend.Backend Proxy (Cloud Run): A Node.js or Python service acting as the WebSocket proxy. It maintains the persistent connection to the Vertex AI Gemini Live API, securely storing GCP service account credentials.AI Engine (Vertex AI): Hosts the gemini-2.5-flash-native-audio model. Configured with response_modalities= to return raw PCM audio directly, bypassing slow TTS pipelines.Semantic Caching (Memorystore for Redis): External API calls (like Open Food Facts) cause conversational latency. Redis is used over Firestore because its in-memory retrieval (sub-millisecond) is required to maintain the illusion of real-time speech. Product barcodes and Additive taxonomy JSONs are cached here.2. Developer Tooling: Gemini CLI & MCPGemini CLI: Used during development to rapidly scaffold Cloud Run Dockerfiles and Terraform scripts.Model Context Protocol (MCP): If the internal product/additive databases grow large, the architecture will utilize Google Cloud's newly released managed MCP servers for Spanner or AlloyDB, allowing the Gemini agent to securely query structured regulatory data without custom API wrappers.3. API Integrations & EndpointsThe architecture implements a Barcode-First strategy to reduce hallucinations and guarantee deterministic data.A. Open Food Facts / Open Beauty Facts API (v2)Primary Lookup (Barcode):GET https://world.openfoodfacts.org/api/v2/product/{barcode}.json?cc=de&lc=de&fields=code,product_name,brands,nutriscore_grade,nova_group,ecoscore_grade,nutriments,ingredients_text,additives_tags(Using cc=de&lc=de filters results and language for the German market)Fallback Search (Text/Vision): If no barcode is visible, the agent reads the label and queries the v1 search endpoint:GET https://world.openfoodfacts.org/cgi/search.pl?search_terms={query}&search_simple=1&json=1&cc=de&lc=de&fields=...4. Tool Calling Schema (Function Declarations)Instead of one massive tool, the system uses compositional function calling with precise JSON schemas to ensure the model gathers exactly what it needs before answering.Tool 1: get_product_by_barcodeJSON{
  "name": "get_product_by_barcode",
  "description": "Fetch structured product data by barcode from Open Food Facts or Open Beauty Facts.",
  "parameters": {
    "type": "OBJECT",
    "properties": {
      "barcode": { "type": "STRING" },
      "domain": { "type": "STRING", "enum": ["food", "beauty"] },
      "country": { "type": "STRING", "description": "Always use 'de'" }
    },
    "required": ["barcode", "domain"]
  }
}
Tool 2: search_products_fulltext (Fallback)JSON{
  "name": "search_products_fulltext",
  "description": "Full-text search for product when barcode is not available.",
  "parameters": {
    "type": "OBJECT",
    "properties": {
      "query": { "type": "STRING", "description": "Product name or brand read from packaging" }
    },
    "required": ["query"]
  }
}
Tool 3: normalize_and_scoreJSON{
  "name": "normalize_and_score",
  "description": "Backend tool that takes raw API JSON, checks the Redis cache for EU additive regulations, and computes NutriVision scores and traffic-light metrics.",
  "parameters": {
    "type": "OBJECT",
    "properties": {
      "raw_product_data": { "type": "OBJECT" }
    },
    "required": ["raw_product_data"]
  }
}
Note: Using a backend tool to do the math (normalize_and_score) ensures the mathematical scoring is perfectly deterministic. The Gemini model is strictly tasked with narrating the result and updating the visual HUD.5. System Instructions (Prompt Engineering)To ensure the correct persona and latency optimizations, the systemInstructions payload initialized over the WebSocket will be strict:"You are NutriVision Live, a strict but helpful German nutritionist and toxicologist. You are seeing a live smartphone camera feed in Germany. Today's date is dynamically provided in your context.1. If you see a barcode, silently trigger get_product_by_barcode. If not, read the label and use search_products_fulltext.2. Once you have data, call normalize_and_score.3. Speak a concise, 2-sentence conversational verdict. Do not read raw numbers unless explicitly asked.4. Visually scan for 'Mindestens haltbar bis (MHD)' or 'Zu verbrauchen bis'. Warn firmly if a 'use-by' date is past today, but suggest a sensory check for an expired MHD.5. If interrupted by the user, stop immediately, process their new question, and answer concisely."